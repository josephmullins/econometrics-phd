{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Hints and Tricks for Assignment 3\n",
    "\n",
    "## Adapting Code for Automatic Differentiation\n",
    "\n",
    "Depending on how much you played around last week, you may have found that methods like `QuadGK` don't play nicely with automatic differentiation. This is because `QuadGK` adjusts the number of nodes adaptively.\n",
    "\n",
    "One solution is to use a fixed number of nodes and weights with `FastGaussQuadrature`. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.224647846541125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using FastGaussQuadrature, QuadGK, ForwardDiff, Distributions, Optim, Roots\n",
    "\n",
    "# a function to integrate using quadrature (default: 10 nodes)\n",
    "function integrateGL(f,a,b ; num_nodes = 10)\n",
    "    nodes, weights = gausslegendre( num_nodes )\n",
    "    ∫f = 0.\n",
    "    for k in eachindex(nodes)\n",
    "        x = (a+b)/2 + (b - a)/2 * nodes[k]\n",
    "        ∫f += weights[k] * f(x)\n",
    "    end\n",
    "    return (b - a)/2 * ∫f\n",
    "end\n",
    "\n",
    "dS(x ; F,β,δ) = (1-cdf(F,x)) / (1-β*(1-δ))\n",
    "res_wage_1(wres , b,λ,δ,β,F) = wres - b - β * λ * integrateGL(x->dS(x;F,β,δ),wres,quantile(F,0.9999))\n",
    "res_wage_2(wres , b,λ,δ,β,F) = wres - b - β * λ * quadgk(x->dS(x;F,β,δ),wres,Inf)[1]\n",
    "\n",
    "ForwardDiff.derivative(x->res_wage_1(x,0.,0.5,0.03,0.99,LogNormal(0,1)),1.) \n",
    "#ForwardDiff.derivative(x->res_wage_2(x,0.,0.5,0.03,0.99,LogNormal(0,1)),1.) <- you can try running this and you will see an error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-writing the model solution\n",
    "\n",
    "Based on this, we're going to re-write the model solution using this new integration routine. We will also use `Roots` to solve for the reservation wage in a way that will also play nicely with `ForwardDiff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45978046027514413"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_wage(wres , b,λ,δ,β,F::Distribution) = wres - b - β * λ * integrateGL(x->dS(x;F,β,δ),wres,quantile(F,0.9999))\n",
    "pars = (;b = -5.,λ = 0.45,δ = 0.03,β = 0.99,F = LogNormal(1,1))\n",
    "\n",
    "\n",
    "function solve_res_wage(b,λ,δ,β,F)\n",
    "    return find_zero(x->res_wage(x,b,λ,δ,β,F),eltype(b)(4.)) #<- initial guess of $4/hour\n",
    "end\n",
    "solve_res_wage(0.,0.4,0.03,0.995,LogNormal())\n",
    "# testing that we can take a derivative here:\n",
    "ForwardDiff.derivative(x->solve_res_wage(x,0.4,0.04,0.995,LogNormal()),0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "None of this is really different from before, but we added a function that pulls a named tuple out for a specific demographic group. You might find that useful for your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(logwage = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.516124491189194, 3.872798692268385, 0.0  …  2.7762279256323206, 0.0, 0.0, 0.0, 2.976307324928243, 0.0, 0.0, 3.410759848526933, 0.0, 0.0], wage_missing = Bool[1, 1, 1, 1, 1, 1, 1, 0, 0, 1  …  0, 1, 1, 1, 0, 1, 1, 0, 1, 1], E = Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], tU = [231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0  …  231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using CSV, DataFrames, DataFramesMeta, Statistics\n",
    "\n",
    "data = CSV.read(\"../data/cps_00019.csv\",DataFrame)\n",
    "data = @chain data begin\n",
    "    @transform :E = :EMPSTAT.<21\n",
    "    @transform @byrow :wage = begin\n",
    "        if :PAIDHOUR==0\n",
    "            return missing\n",
    "        elseif :PAIDHOUR==2\n",
    "            if :HOURWAGE<99.99 && :HOURWAGE>0\n",
    "                return :HOURWAGE\n",
    "            else\n",
    "                return missing\n",
    "            end\n",
    "        elseif :PAIDHOUR==1\n",
    "            if :EARNWEEK>0 && :UHRSWORKT<997 && :UHRSWORKT>0\n",
    "                return :EARNWEEK / :UHRSWORKT\n",
    "            else\n",
    "                return missing\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @subset :MONTH.==1\n",
    "    @select :AGE :SEX :RACE :EDUC :wage :E :DURUNEMP\n",
    "    @transform begin\n",
    "        :bachelors = :EDUC.>=111\n",
    "        :nonwhite = :RACE.!=100 \n",
    "        :female = :SEX.==2\n",
    "        :DURUNEMP = round.(:DURUNEMP .* 12/52)\n",
    "    end\n",
    "end\n",
    "\n",
    "# the whole dataset in a named tuple\n",
    "wage_missing = ismissing.(data.wage)\n",
    "wage = coalesce.(data.wage,1.)\n",
    "N = length(data.AGE)\n",
    "X = [ones(N) data.bachelors data.female data.nonwhite]\n",
    "# create a named tuple with all variables to conveniently pass to the log-likelihood:\n",
    "d = (;logwage = log.(wage),wage_missing,E = data.E,tU = data.DURUNEMP, X) #<- you will need to add your demographics as well.\n",
    "\n",
    "function get_data(data,C,F,R)\n",
    "    data = @subset data :bachelors.==C :female.==F :nonwhite.==R\n",
    "    wage_missing = ismissing.(data.wage)\n",
    "    wage = coalesce.(data.wage,1.)\n",
    "    N = length(data.AGE)\n",
    "    # create a named tuple with all variables to conveniently pass to the log-likelihood:\n",
    "    return d = (;logwage = log.(wage),wage_missing,E = data.E,tU = data.DURUNEMP) \n",
    "end\n",
    "\n",
    "dx = get_data(data,1,0,0) #<- data for white men with a college degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the log-likelihood with one set of parameters\n",
    "\n",
    "In your assignment you will estimate the model for one set of demographic characteristics by directly estimating $(h,\\delta,\\mu,\\sigma,w^*)$ and backing out $b$ and $\\lambda$. Here is a log-likelihood function that you could use (feel free to write your own)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_likelihood_obj (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ϕ(x,μ,σ) = pdf(Normal(μ,σ),x)\n",
    "Φ(x,μ,σ) = cdf(Normal(μ,σ),x)\n",
    "# a function for the log-likelihood of observed wages (integrating out measurement error)\n",
    "function logwage_likelihood(logwage,F,σζ,wres)\n",
    "    f(x) = pdf(F,x) / (1-cdf(F,wres)) * ϕ(logwage,log(x),σζ)\n",
    "    ub = quantile(F,0.9999)\n",
    "    return integrateGL(f,wres,ub)\n",
    "end\n",
    "# a function to get the log-likelihood of a single observation\n",
    "function log_likelihood(n,data,pars)\n",
    "    (;h,δ,wres,F,σζ) = pars\n",
    "    ll = 0.\n",
    "    if data.E[n]\n",
    "        ll += log(h) - log(h + δ)\n",
    "        if !data.wage_missing[n]\n",
    "            ll += logwage_likelihood(data.logwage[n],F,σζ,wres)\n",
    "        end\n",
    "    else\n",
    "        ll += log(δ) - log(h + δ)\n",
    "        ll += log(h) + data.tU[n] * log(1-h)\n",
    "    end\n",
    "    return ll\n",
    "end\n",
    "\n",
    "# a function to map the vector x into parameters\n",
    "logit(x) = exp(x) / (1+exp(x))\n",
    "logit_inv(x) = log(x/(1-x))\n",
    "function update(pars,x)\n",
    "    h = logit(x[1])\n",
    "    δ = logit(x[2])\n",
    "    μ = x[3]\n",
    "    σ = exp(x[4])\n",
    "    wres = exp(x[5])\n",
    "    F = LogNormal(μ,σ)\n",
    "    σζ = 0.05\n",
    "    return (;pars...,h,δ,μ,σ,wres,F,σζ)\n",
    "end\n",
    "# a function to iterate over all observations\n",
    "function log_likelihood_obj(x,pars,data)\n",
    "    pars = update(pars,x)\n",
    "    ll = 0.\n",
    "    for n in eachindex(data.E)\n",
    "        ll += log_likelihood(n,data,pars)\n",
    "    end\n",
    "    return ll / length(data.E)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this log-likelihood we can pass straight to `Optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     1.566021e-01     9.112564e-02\n",
      " * time: 8.916854858398438e-5\n",
      "     1     1.124900e-01     8.425665e-02\n",
      " * time: 0.18092608451843262\n",
      "     2     9.438133e-02     7.424673e-02\n",
      " * time: 0.3399372100830078\n",
      "     3     7.262438e-02     9.064264e-02\n",
      " * time: 0.49828410148620605\n",
      "     4     6.527359e-02     4.043801e-01\n",
      " * time: 0.6780951023101807\n",
      "     5     5.390735e-02     7.264660e-02\n",
      " * time: 0.8790051937103271\n",
      "     6     4.456252e-02     5.104587e-02\n",
      " * time: 1.2180511951446533\n",
      "     7     4.419638e-02     4.246399e-02\n",
      " * time: 1.492077112197876\n",
      "     8     4.331776e-02     9.864366e-02\n",
      " * time: 1.6455280780792236\n",
      "     9     4.279575e-02     8.358208e-02\n",
      " * time: 1.8211140632629395\n",
      "    10     4.266464e-02     3.147197e-02\n",
      " * time: 1.9958012104034424\n",
      "    11     4.263086e-02     1.838941e-02\n",
      " * time: 2.1707379817962646\n",
      "    12     4.262640e-02     3.127715e-03\n",
      " * time: 2.3470070362091064\n",
      "    13     4.262633e-02     3.959605e-07\n",
      " * time: 2.499476194381714\n",
      "    14     4.262633e-02     2.184184e-08\n",
      " * time: 2.674283981323242\n",
      "    15     4.262633e-02     7.462975e-10\n",
      " * time: 2.744335174560547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     4.262633e-02\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Newton's Method\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 6.68e-08 ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = 1.20e-08 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 8.81e-15 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 2.07e-13 ≰ 0.0e+00\n",
       "    |g(x)|                 = 7.46e-10 ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   3  (vs limit Inf)\n",
       "    Iterations:    15\n",
       "    f(x) calls:    54\n",
       "    ∇f(x) calls:   54\n",
       "    ∇²f(x) calls:  15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = [logit_inv(0.5),logit_inv(0.03),2.,log(1.),log(5.)]\n",
    "pars = (;σζ = 0.05, β = 0.995)\n",
    "log_likelihood_obj(x0,pars,dx) #<- test.\n",
    "res = optimize(x->-log_likelihood_obj(x,pars,dx),x0,Newton(),Optim.Options(show_trace=true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(σζ = 0.05, h = 0.17641764242681596, δ = 0.003828372201989135, μ = 2.416002041470427, σ = 1.147127370295339, wres = 18.6280911963576, F = LogNormal{Float64}(μ=2.416002041470427, σ=1.147127370295339))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pars = update(pars,res.minimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could back out estimates of $b$ and $\\lambda$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-601.9015559474371"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "λ = pars.h / (1 - cdf(pars.F,pars.wres))\n",
    "b = pars.wres - pars.β * λ * integrateGL(x->dS(x;pars.F,pars.β,pars.δ),pars.wres,quantile(pars.F,0.9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about standard errors? Some parameters (such as $\\delta$) are transformations of the estimated vector. Here we need the delta method, which tells us that if $\\mathbb{V}(\\hat{\\theta}) = v$ and $\\beta = f(\\theta)$ then $\\mathbb{V}(\\hat{\\beta}) = f'(\\theta)^2v$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00037289231946497606"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "H = ForwardDiff.hessian(x->log_likelihood_obj(x,pars,dx),res.minimizer)\n",
    "N = length(dx.E)\n",
    "avar = inv(-H) #<- asymptotic variance estimate\n",
    "std_err_δ = pars.δ * sqrt(avar[2,2] / N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final note. You could automate this whole calculation by writing a function that returns all your transformed parameters of interest as a function of the estimated vector, then calling `ForwardDiff`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>7×3 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">par</th><th style = \"text-align: left;\">est</th><th style = \"text-align: left;\">se</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">h</td><td style = \"text-align: right;\">0.176418</td><td style = \"text-align: right;\">0.0114358</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">δ</td><td style = \"text-align: right;\">0.00382837</td><td style = \"text-align: right;\">0.000371465</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">μ</td><td style = \"text-align: right;\">2.416</td><td style = \"text-align: right;\">0.167726</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">σ</td><td style = \"text-align: right;\">1.14713</td><td style = \"text-align: right;\">0.044975</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">wres</td><td style = \"text-align: right;\">18.6281</td><td style = \"text-align: right;\">0.178748</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">λ</td><td style = \"text-align: right;\">0.536668</td><td style = \"text-align: right;\">0.0841872</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">b</td><td style = \"text-align: right;\">-601.902</td><td style = \"text-align: right;\">31.4198</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& par & est & se\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & h & 0.176418 & 0.0114358 \\\\\n",
       "\t2 & δ & 0.00382837 & 0.000371465 \\\\\n",
       "\t3 & μ & 2.416 & 0.167726 \\\\\n",
       "\t4 & σ & 1.14713 & 0.044975 \\\\\n",
       "\t5 & wres & 18.6281 & 0.178748 \\\\\n",
       "\t6 & λ & 0.536668 & 0.0841872 \\\\\n",
       "\t7 & b & -601.902 & 31.4198 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m7×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m par    \u001b[0m\u001b[1m est           \u001b[0m\u001b[1m se           \u001b[0m\n",
       "     │\u001b[90m String \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Float64      \u001b[0m\n",
       "─────┼─────────────────────────────────────\n",
       "   1 │ h          0.176418     0.0114358\n",
       "   2 │ δ          0.00382837   0.000371465\n",
       "   3 │ μ          2.416        0.167726\n",
       "   4 │ σ          1.14713      0.044975\n",
       "   5 │ wres      18.6281       0.178748\n",
       "   6 │ λ          0.536668     0.0841872\n",
       "   7 │ b       -601.902       31.4198"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "function final_ests(x_est,pars)\n",
    "    pars = update(pars,x_est)\n",
    "    (;h,δ,μ,σ,wres,F,β) = pars\n",
    "    λ = h / (1 - cdf(F,wres))\n",
    "    b = wres - β * λ * integrateGL(x->dS(x;F,β,δ),wres,quantile(F,0.9999))\n",
    "    return [h , δ, μ, σ, wres, λ, b]\n",
    "end\n",
    "dF = ForwardDiff.jacobian(x->final_ests(x,pars),res.minimizer)\n",
    "var_est = dF * avar * dF' / N #<- this is the variance of the estimates implied by the delta method\n",
    "# now a table with estimates and standard errors:\n",
    "p_str = [\"h\",\"δ\",\"μ\",\"σ\",\"wres\",\"λ\",\"b\"]\n",
    "DataFrame(par = p_str,est = final_ests(res.minimizer,pars),se = sqrt.(diag(var_est)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
